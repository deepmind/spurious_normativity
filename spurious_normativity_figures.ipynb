{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SXEt5HTJEfJY"
      },
      "source": [
        "Copyright 2021 DeepMind Technologies Limited.\n",
        "\n",
        "Licensed under the Apache License, Version 2.0 (the \"License\"); you may not use this file except in compliance with the License. You may obtain a copy of the License at\n",
        "\n",
        "https://www.apache.org/licenses/LICENSE-2.0\n",
        "\n",
        "Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3EU7h3G7bCNK"
      },
      "source": [
        "This colab accompanies the paper 'Spurious normativity enhances learning of compliance and enforcement behavior in artificial agents' in PNAS 2022 by Koster et al."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SyjlbfU8Wmrj"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pickle\n",
        "import scipy.stats\n",
        "import seaborn as sns\n",
        "import tempfile\n",
        "from google.colab import files\n",
        "import warnings\n",
        "warnings.simplefilter('ignore', category=RuntimeWarning)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OB3wc0QkFJPg"
      },
      "source": [
        "# Load Data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SXio39N0xOhX"
      },
      "outputs": [],
      "source": [
        "f = tempfile.NamedTemporaryFile()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vcm5RC8IOTGP"
      },
      "outputs": [],
      "source": [
        "!gsutil cp \"gs://dm_spurious_normativity/spurious_normativity.pkl\" {f.name}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5l9ysaAAOUij"
      },
      "outputs": [],
      "source": [
        "with open(f.name, 'rb') as pickle_file:\n",
        "  data = pickle.load(pickle_file)\n",
        "population_data = data[0]\n",
        "probe_data = data[1]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WdCpM38SWmOh"
      },
      "source": [
        "# Population Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y9LCjtQ2T4UW"
      },
      "source": [
        "population_data contains data from the 3 conditions: \n",
        "\n",
        "* 'no rule', \n",
        "* 'important rule',\n",
        "* 'silly rule'\n",
        "\n",
        "Each of those conditions has 7 variables that were logged for each\n",
        "population.\n",
        "\n",
        "* Collective Return\n",
        "* Total Berries Eaten\n",
        "* Total Taboo Berries Eaten\n",
        "* Total Punishments\n",
        "* Total Misdirected Punishing\n",
        "* Fraction of Time Spent Marked\n",
        "* Fracton of Time Spent Poisoned\n",
        "\n",
        "Each entry is indexed by a combination of the condition and metric, e.g.:\n",
        "'important rule Collective Return'\n",
        "\n",
        "Each of those entries contains a list, containing different populations.\n",
        "5 for no rule, 15 for the other two conditions.\n",
        "\n",
        "Each population consists of a tuple: the data of the x and y axis to plot this metric in that particular condition of one population.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7GFZIgzYWgl0"
      },
      "source": [
        "# Probe data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ao-hvLvYT0Bj"
      },
      "source": [
        "probe_data contains 15 variables that respond to a probe task in one\n",
        "experimental condition. The variables are, for the no rules condition:\n",
        "\n",
        " * 'no_rule_berry_1' - how quickly berry 1 was approached, the actually poisonous berry.\n",
        "\n",
        "* 'no_rule_berry_2' - how quickly berry 2 was approached, the harmless berry that\n",
        "  is taboo in the silly rules condition.\n",
        "\n",
        "* 'no_rule_berry_healthy' - how quickly other berries were approached.\n",
        "\n",
        "* 'no_rule_zap_marked' - how quickly a marked player was zapped.\n",
        "\n",
        "* 'no_rule_zap_unmarked' - how quickly the unmarked players were zapped.\n",
        "\n",
        "These metrics are repeated for the important_rule and silly_rule condition:\n",
        "\n",
        "* 'important_rule_berry_1'\n",
        "\n",
        "* 'important_rule_berry_2'\n",
        "\n",
        "* 'important_rule_healthy'\n",
        "\n",
        "* 'important_zap_marked'\n",
        "\n",
        "* 'important_zap_unmarked'\n",
        "\n",
        "* 'silly_rule_berry_1'\n",
        "\n",
        "* 'silly_rule_berry_2'\n",
        "\n",
        "* 'silly_rule_healthy'\n",
        "  \n",
        "* 'silly_zap_marked'\n",
        "\n",
        "* 'silly_zap_unmarked'\n",
        "\n",
        "Each entry contains an array with the shape [N, 20]. N is the number of\n",
        "independent populations that were run and the 20 refers to the number of samples\n",
        "along the training trajectory for which the probes were ran. N = 5 for no_rule\n",
        "and N = 15 for silly_rule and important_rule."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "agh626hIZxw8"
      },
      "source": [
        "# Figure 4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gM5A3Sd5nqyH"
      },
      "outputs": [],
      "source": [
        "n_rows = 2\n",
        "n_cols = 3\n",
        "\n",
        "condition_legends = ['no rule', 'important rule', 'silly rule']\n",
        "colors_per_condition = [(.8, .9, 25./255),\n",
        "                        (230./255, 25./255, 75./255),\n",
        "                        (60./255, 180./255, 75./255)]\n",
        "\n",
        "metrics_titles = ['Total Misdirected Punishing',\n",
        "                  'Total Punishments',\n",
        "                  'Fraction of Time Spent Marked',\n",
        "                  'Fracton of Time Spent Poisoned',\n",
        "                  'Total Taboo Berries Eaten',\n",
        "                  'Collective Return']\n",
        "\n",
        "alphabet = ['A. ', 'B. ', 'C. ', 'D. ', 'E. ', 'F. ']\n",
        "y_lims_per_metric = [(0, 10),\n",
        "                     (0, 60),\n",
        "                     (0, 1),\n",
        "                     (0, 0.7),\n",
        "                     (0, 120),\n",
        "                     (0, 5500)]\n",
        "\n",
        "plotcounter = 1\n",
        "plt.figure(facecolor='white')\n",
        "fig, ax = plt.subplots(n_rows, n_cols, figsize=(25, n_rows*7), facecolor='w')\n",
        "for metric, letter, y_lims in zip(\n",
        "    metrics_titles, alphabet, y_lims_per_metric):\n",
        "  plt.subplot(n_rows, n_cols, plotcounter)\n",
        "  for condition, line_color in zip(condition_legends, colors_per_condition):\n",
        "    entry = condition + ' ' + metric\n",
        "    condition_data = population_data[entry]\n",
        "    # The data do not have the same shape so we need to put them on a\n",
        "    # canvas of nans to concatenate them.\n",
        "    data_frame_for_mean = np.empty((int(1e5), len(condition_data)))\n",
        "    data_frame_for_mean.fill(np.nan)\n",
        "    for p, population in enumerate(condition_data):\n",
        "      trajectory = condition_data[p][1]\n",
        "      data_frame_for_mean[0:trajectory.shape[0], p] = trajectory\n",
        "\n",
        "    y = np.nanmean(data_frame_for_mean, axis=1)\n",
        "    # SEM\n",
        "    y_error = np.divide(\n",
        "        np.nanstd(data_frame_for_mean, axis=1),\n",
        "        np.sqrt(len(condition_data)))\n",
        "    x = np.arange(0, 1e9, 1e4)\n",
        "    plt.plot(x, y, color=line_color)\n",
        "    plt.fill_between(x, y-y_error, y+y_error, alpha=0.4,\n",
        "                     color=line_color, label='_nolegend_')\n",
        "  plt.title(letter +  metric, fontsize=18, fontweight='bold')\n",
        "  plt.legend(condition_legends, loc='best', fontsize=12)\n",
        "  plt.xlabel('Timesteps trained', fontsize=14)\n",
        "  plt.xlim(0, 1e9)\n",
        "  plt.ylim(y_lims)\n",
        "  plt.xticks(fontsize=14)\n",
        "  plt.yticks(fontsize=14)\n",
        "  plotcounter += 1\n",
        "\n",
        "plt.savefig('fig4.png', dpi=500)\n",
        "files.download('fig4.png')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kvyzoR9vjpBr"
      },
      "outputs": [],
      "source": [
        "# Statistics for Fig 4 plot, t-tests per timebin\n",
        "populations = 15\n",
        "timebins = 10\n",
        "start_x = 0\n",
        "end_x = 1e8\n",
        "\n",
        "for tb in range(timebins):\n",
        "  silly_means = np.zeros((populations))\n",
        "  important_means = np.zeros((populations))\n",
        "\n",
        "  for p in range(populations):\n",
        "    silly_x = population_data['silly rule Collective Return'][p][0]\n",
        "    silly_y = population_data['silly rule Collective Return'][p][1]\n",
        "    silly_index = (silly_x \u003e start_x) \u0026 (silly_x \u003c end_x)\n",
        "    silly_mean = np.nanmean(silly_y[silly_index])\n",
        "    silly_means[p] = silly_mean\n",
        "\n",
        "    important_x = population_data['important rule Collective Return'][p][0]\n",
        "    important_y = population_data['important rule Collective Return'][p][1]\n",
        "    important_index = (important_x \u003e start_x) \u0026 (important_x \u003c end_x)\n",
        "    important_mean = np.nanmean(important_y[important_index])\n",
        "    important_means[p] = important_mean\n",
        "\n",
        "  t, p = scipy.stats.ttest_ind(silly_means, important_means)\n",
        "  print('For timebin ', tb+1, ' from ', start_x, ' to ', end_x)\n",
        "  print('Difference between silly and important rule condition:')\n",
        "  print('t =', np.round(t, decimals=3), ', p =', np.round(p, decimals=4))\n",
        "\n",
        "  start_x += 1e8\n",
        "  end_x += 1e8"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-QX6cACZZqx3"
      },
      "source": [
        "# Figure 5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HIS_Za6SP-oC"
      },
      "outputs": [],
      "source": [
        "fig_5_conditions = ['important rule', 'silly rule']\n",
        "fig_5_metrics = ['Total Punishments', 'Fracton of Time Spent Poisoned']\n",
        "cutoffs = [(0, 2e8), (2e8, 4e8)]\n",
        "data_for_correlation = {}\n",
        "for condition in fig_5_conditions:\n",
        "  for metric, cutoff in zip(fig_5_metrics, cutoffs):\n",
        "    entry_name = condition + ' ' + metric\n",
        "    data_in_entry = population_data[entry_name]\n",
        "    mean_values = np.zeros(len(data_in_entry))\n",
        "    for i, d in enumerate(data_in_entry):\n",
        "      x = d[0]\n",
        "      y = d[1]\n",
        "      index_vec = np.where((x \u003e cutoff[0]) \u0026 (x \u003c cutoff[1]))\n",
        "      mean_values[i] = np.mean(y[index_vec])\n",
        "    data_for_correlation[entry_name] = mean_values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g7Jz_8QWakiE"
      },
      "outputs": [],
      "source": [
        "fig = plt.figure(figsize=(5, 5), facecolor='white')\n",
        "ax = fig.add_subplot(111)\n",
        "sns.regplot(x=data_for_correlation['silly rule Fracton of Time Spent Poisoned'],\n",
        "            y=data_for_correlation['silly rule Total Punishments'],\n",
        "            color='green')\n",
        "sns.regplot(x=data_for_correlation['important rule Fracton of Time Spent Poisoned'],\n",
        "            y=data_for_correlation['important rule Total Punishments'],\n",
        "            color='red')\n",
        "plt.xlabel('Fraction of time spent poisoned (later)', fontsize=12)\n",
        "plt.ylabel('Punishments of players (early)', fontsize=12, labelpad=0)\n",
        "\n",
        "plt.title('Early punishment reduces later poisoning', fontweight='bold')\n",
        "plt.legend(['silly rule', 'important rule'], loc='upper right')\n",
        "plt.xticks([0, .2, .4, .6])\n",
        "\n",
        "plt.savefig('fig5.png', dpi=500)\n",
        "files.download('fig5.png')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QqO6pqCrYsfd"
      },
      "outputs": [],
      "source": [
        "# Statistics for Fig 5 plot\n",
        "sr_corr_pop = scipy.stats.pearsonr(\n",
        "    data_for_correlation['silly rule Fracton of Time Spent Poisoned'],\n",
        "    data_for_correlation['silly rule Total Punishments'])\n",
        "\n",
        "ir_corr_pop = scipy.stats.pearsonr(\n",
        "    data_for_correlation['important rule Fracton of Time Spent Poisoned'],\n",
        "    data_for_correlation['important rule Total Punishments'])\n",
        "\n",
        "print('Silly Rule: r =', np.round(sr_corr_pop[0], decimals=3),\n",
        "      'p =', np.round(sr_corr_pop[1], decimals=3))\n",
        "\n",
        "print('Important Rule: r =', np.round(ir_corr_pop[0], decimals=3),\n",
        "      'p =', np.round(ir_corr_pop[1], decimals=3))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xTMiwX5qakrx"
      },
      "source": [
        "# Figure 6"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e-klkWRqgxpX"
      },
      "outputs": [],
      "source": [
        "def error_line(var, color):\n",
        "  ym = np.mean(var, axis=0)\n",
        "  plt.plot(ym, color=color)\n",
        "  ye = np.divide(np.nanstd(var, axis=0), np.sqrt(5))\n",
        "  # x axis is always 20\n",
        "  # because that is how often the agent was sampled during learning\n",
        "  plt.fill_between(range(20), ym-ye, ym+ye, alpha=0.2, color=color)\n",
        "\n",
        "def populate_axis():\n",
        "  plt.ylim((0, 1))\n",
        "  y_label = 'Timesteps until termination'\n",
        "  plt.ylabel(y_label, fontsize=12, labelpad=-10)\n",
        "  plt.yticks([0, 1], [0, 1])\n",
        "  plt.yticks([0, 1], [30, 0])\n",
        "\n",
        "  plt.xlim((0, 20))\n",
        "  plt.xlabel('Timesteps trained', fontsize=12, labelpad=-10)\n",
        "  plt.xticks([0, 20], ['0', '1e9'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rNx10qHRalRT"
      },
      "outputs": [],
      "source": [
        "plt.figure(facecolor='w')\n",
        "fig, ax = plt.subplots(2, 3, figsize=(15, 10), facecolor='w')\n",
        "\n",
        "plt.subplot(2, 3, 1)\n",
        "error_line(probe_data['no_rule_berry_1'], 'pink')\n",
        "error_line(probe_data['no_rule_berry_2'], 'teal')\n",
        "error_line(probe_data['no_rule_berry_healthy'], 'blue')\n",
        "populate_axis()\n",
        "plt.legend(['Poisonous',\n",
        "            'Healthy in this condition',\n",
        "            'Healthy in all conditions'])\n",
        "plt.title('B. Berries: No Rule', fontweight='bold')\n",
        "\n",
        "plt.subplot(2, 3, 2)\n",
        "error_line(probe_data['important_rule_berry_1'], 'pink')\n",
        "error_line(probe_data['important_rule_berry_2'], 'teal')\n",
        "error_line(probe_data['important_rule_healthy'], 'blue')\n",
        "populate_axis()\n",
        "plt.legend(['Poisonous and Taboo',\n",
        "            'Healthy in this condition',\n",
        "            'Healthy in all conditions'])\n",
        "plt.title('C. Berries: Important Rule', fontweight='bold')\n",
        "\n",
        "plt.subplot(2, 3, 3)\n",
        "error_line(probe_data['silly_rule_berry_1'], 'pink')\n",
        "error_line(probe_data['silly_rule_berry_2'], 'teal')\n",
        "error_line(probe_data['silly_rule_healthy'], 'blue')\n",
        "populate_axis()\n",
        "plt.legend(['Poisonous and Taboo',\n",
        "            'Taboo in this condition',\n",
        "            'Healthy in all conditions'])\n",
        "plt.title('D. Berries: Silly Rule', fontweight='bold')\n",
        "\n",
        "plt.subplot(2, 3, 4)\n",
        "error_line(probe_data['important_rule_berry_1'], 'red')\n",
        "error_line(probe_data['silly_rule_berry_1'], 'green')\n",
        "populate_axis()\n",
        "plt.legend(['important rule', 'silly rule'])\n",
        "plt.title('E. Poison berry', fontweight='bold')\n",
        "\n",
        "plt.subplot(2, 3, 5)\n",
        "error_line(probe_data['important_zap_marked'], 'red')\n",
        "error_line(probe_data['silly_zap_marked'], 'green')\n",
        "populate_axis()\n",
        "plt.legend(['important rule', 'silly rule'])\n",
        "plt.title('F. Punishing marked player', fontweight='bold')\n",
        "\n",
        "marked_player_important_mean = np.mean(\n",
        "    probe_data['important_zap_marked'][:, 0:4], axis=1)\n",
        "marked_player_silly_mean = np.mean(\n",
        "    probe_data['silly_zap_marked'][:, 0:4], axis=1)\n",
        "\n",
        "berry1_important_mean = np.mean(\n",
        "    probe_data['important_rule_berry_1'][:, 4:8], axis=1)\n",
        "berry_1_silly_mean = np.mean(\n",
        "    probe_data['silly_rule_berry_1'][:, 4:8], axis=1)\n",
        "\n",
        "ax = plt.subplot(2, 3, 6)\n",
        "# Multiply values by 30 because the probe episodes have 30 timesteps.\n",
        "sns.regplot(x=berry_1_silly_mean*30, y=marked_player_silly_mean*30,\n",
        "            color='green', label='silly rule')\n",
        "sns.regplot(x=berry1_important_mean*30, y=marked_player_important_mean*30,\n",
        "            color='red', label='important rule')\n",
        "plt.xlabel('Timesteps to approach poisoned berry (later)', fontsize=12)\n",
        "plt.ylabel('Timesteps to punish marked player (early)', fontsize=12, labelpad=0)\n",
        "plt.xticks([0, 5, 10, 15], [30, 25, 20, 15])\n",
        "plt.yticks([2, 5, 8], [28, 25, 22])\n",
        "plt.title('G. Early punishment reduces later poisoning', fontweight='bold')\n",
        "h, l = ax.get_legend_handles_labels()\n",
        "ax.legend(reversed(h), reversed(l), loc='upper right')\n",
        "\n",
        "plt.savefig('fig6.png', dpi=500)\n",
        "files.download('fig6.png')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3bBMC21M2rEE"
      },
      "outputs": [],
      "source": [
        "# Stats for Figure 6 F\n",
        "sr_corr_probe = scipy.stats.pearsonr(\n",
        "    berry_1_silly_mean, marked_player_silly_mean)\n",
        "ir_corr_probe = scipy.stats.pearsonr(\n",
        "    berry1_important_mean, marked_player_important_mean)\n",
        "\n",
        "print('Silly Rule: r =', np.round(sr_corr_probe[0], decimals=3),\n",
        "      'p =', np.round(sr_corr_probe[1], decimals=3))\n",
        "\n",
        "print('Important Rule: r =', np.round(ir_corr_probe[0], decimals=3),\n",
        "      'p =', np.round(ir_corr_probe[1], decimals=3))"
      ]
    }
  ],
  "metadata": {},
  "nbformat": 4,
  "nbformat_minor": 0
}
